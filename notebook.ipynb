{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/VahidZee/DRMADE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd DRMADE/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch as t\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "\n",
    "from src.utils.data import DatasetSelection\n",
    "from src.model.model import DRMADE\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "batch_size = config.batch_size\n",
    "test_batch_size = config.test_batch_size\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "hidden_layers = config.made_hidden_layers\n",
    "num_masks = config.made_num_masks\n",
    "num_mix = config.num_mix\n",
    "latent_size = config.latent_size\n",
    "\n",
    "latent_regularization_factor = config.latent_regularization_factor\n",
    "noise_factor = config.noising_factor\n",
    "\n",
    "base_lr = config.base_lr\n",
    "lr_decay = config.lr_decay\n",
    "lr_half_schedule = config.lr_half_schedule\n",
    "\n",
    "# accessory functions\n",
    "noise_function = lambda x: noise_factor * (\n",
    "        2 * t.FloatTensor(*x).to(device).uniform_() - 1)  # (x will be the input shape tuple)\n",
    "lr_multiplicative_factor_lambda = lambda epoch: 0.5 if (epoch + 1) % lr_half_schedule == 0 else lr_decay\n",
    "\n",
    "# reproducibility\n",
    "t.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "\n",
    "# type initialization\n",
    "t.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading training data')\n",
    "train_data = DatasetSelection(datasets.MNIST, classes=config.normal_classes, train=True)\n",
    "print('loading validation data')\n",
    "validation_data = DatasetSelection(datasets.MNIST, classes=config.normal_classes, train=False)\n",
    "print('loading test data')\n",
    "test_data = DatasetSelection(datasets.MNIST, train=False)\n",
    "\n",
    "input_shape = train_data.input_shape()\n",
    "\n",
    "print('initializing data loaders')\n",
    "train_loader = train_data.get_dataloader(shuffle=True)\n",
    "validation_loader = validation_data.get_dataloader(shuffle=False)\n",
    "test_loader = test_data.get_dataloader(shuffle=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('initializing model')\n",
    "model = DRMADE(input_shape[0], latent_size, hidden_layers, num_masks=num_masks, num_mix=num_mix)\n",
    "\n",
    "# setting up tensorboard data summerizer\n",
    "model_name = f'{model.name}-rl={latent_regularization_factor}-nz={noise_factor}-Adam,lr={base_lr},dc={lr_decay},s={lr_half_schedule}'\n",
    "writer = SummaryWriter(\n",
    "    log_dir=config.runs_dir + f'/{model_name}')\n",
    "\n",
    "print('initializing optimizer')\n",
    "optimizer = Adam(model.parameters(), lr=base_lr)\n",
    "print('initializing learning rate scheduler')\n",
    "scheduler = lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lr_multiplicative_factor_lambda, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epoch):\n",
    "    train_loss = 0.0\n",
    "    time_ = time.time()\n",
    "    for batch_idx, (images, _) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        if noise_factor:\n",
    "            noisy_images = images + noise_function(images.shape)\n",
    "            noisy_images.clamp_(min=-1, max=1)\n",
    "\n",
    "        loss = 0.0\n",
    "        for i in range(num_masks):\n",
    "            model.made.update_masks()\n",
    "            if noise_factor:\n",
    "                output, noised_features = model(noisy_images)\n",
    "                features = model.encoder(images)\n",
    "            else:\n",
    "                output, features = model(images)\n",
    "            loss += -model.log_prob(features, output) + latent_regularization_factor * model.latent_regularization_term(\n",
    "                features)\n",
    "        loss /= num_masks\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss / batch_size\n",
    "        if config.log_train_loop_interval and (batch_idx + 1) % config.log_train_loop_interval == 0:\n",
    "            print(\n",
    "                '\\t{:3d}/{:3d} - loss : {:.4f}, time : {:.3f}s'.format(\n",
    "                    batch_idx, len(train_loader), train_loss / (1 + batch_idx), time.time() - time_)\n",
    "            )\n",
    "            time_ = time.time()\n",
    "    return train_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(epoch):\n",
    "    validation_loss = 0.0\n",
    "    time_ = time()\n",
    "    with t.no_grad():\n",
    "        for batch_idx, (images, _) in enumerate(validation_loader):\n",
    "            images = images.to(device)\n",
    "            loss = 0.0\n",
    "            for i in range(num_masks):\n",
    "                model.made.update_masks()\n",
    "                output, features = model(images)\n",
    "                loss += -model.log_prob(features,\n",
    "                                        output) + latent_regularization_factor * model.latent_regularization_term(\n",
    "                    features)\n",
    "            loss /= num_masks\n",
    "            validation_loss += loss / batch_size\n",
    "            if config.log_validation_loop_interval and (batch_idx + 1) % config.log_validation_loop_interval == 0:\n",
    "                print(\n",
    "                    '\\t{:3d}/{:3d} - loss : {:.4f}, time : {:.3f}s'.format(\n",
    "                        batch_idx, len(validation_loader), validation_loss / (1 + batch_idx), time.time() - time_)\n",
    "                )\n",
    "                time_ = time.time()\n",
    "    return validation_loss / len(validation_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loop(epoch):\n",
    "    with t.no_grad():\n",
    "        scores = t.Tensor().to(device)\n",
    "        labels = np.empty(0, dtype=np.int8)\n",
    "        time_ = time.time()\n",
    "        for batch_idx, (images, label) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            output, features = model(images)\n",
    "            scores = t.cat((scores, model.log_prob_hitmap(features, output).sum(1)), dim=0)\n",
    "            labels = np.append(labels, label.numpy().astype(np.int8), axis=0)\n",
    "            if config.log_evaluation_loop_interval and (batch_idx + 1) % config.log_evaluation_loop_interval == 0:\n",
    "                print(\n",
    "                    '\\t{:3d}/{:3d} - time : {:.3f}s'.format(\n",
    "                        batch_idx, len(test_loader), time.time() - time_)\n",
    "                )\n",
    "                time_ = time.time()\n",
    "        is_pos = np.isin(labels, [8])\n",
    "    return scores, is_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(config.max_epoch):\n",
    "        print('epoch {:4} - lr: {}'.format(epoch, optimizer.param_groups[0][\"lr\"]))\n",
    "        train_loss = train_loop(epoch)\n",
    "        validation_loss = validation_loop(epoch)\n",
    "        writer.add_scalars('loss', {'validation': validation_loss, 'training': train_loss})\n",
    "        if config.save_interval and (epoch + 1) % config.save_interval == 0:\n",
    "            model.save(config.models_dir + f'/{model_name}-E{epoch}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
